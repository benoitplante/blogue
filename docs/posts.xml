<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Benoit Plante</title>
<link>https://benoitplante.github.io/blogue/posts.html</link>
<atom:link href="https://benoitplante.github.io/blogue/posts.xml" rel="self" type="application/rss+xml"/>
<description>RÃ©flexions, cas dâ€™usage et outils Ã  lâ€™interface entre IA et psychologie</description>
<generator>quarto-1.7.31</generator>
<lastBuildDate>Mon, 26 May 2025 04:00:00 GMT</lastBuildDate>
<item>
  <title>ReconnaÃ®tre la personnalitÃ© Ã  partir de textes? Une Ã©tude prometteuse avec les modÃ¨les transformers</title>
  <link>https://benoitplante.github.io/blogue/posts/2025-05-29-personnalite-transformer/</link>
  <description><![CDATA[ 





<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://benoitplante.github.io/blogue/posts/2025-05-29-personnalite-transformer/banner_article_electra.png" class="img-fluid figure-img"></p>
<figcaption>GÃ©nÃ©rÃ©e par ChatGPT</figcaption>
</figure>
</div>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">Introduction</h2>
<p>Peut-on prÃ©dire les traits de personnalitÃ© dâ€™une personne simplement Ã  partir dâ€™un texte quâ€™elle a Ã©crit? Cette question, qui pourrait sembler tirÃ©e dâ€™un film de science-fiction, est aujourdâ€™hui au cÅ“ur de recherches sÃ©rieuses en psychologie computationnelle. Jâ€™ai rÃ©cemment lu une Ã©tude fascinante prÃ©sentÃ©e Ã  la confÃ©rence <em>IEEE ICWR 2025</em>, qui explore cette idÃ©e Ã  lâ€™aide dâ€™un modÃ¨le dâ€™intelligence artificielle appelÃ© <strong>ELECTRA</strong>, une version moderne des modÃ¨les transformers.</p>
<p>Dans ce billet, je prÃ©sente lâ€™article en question ainsi que la technologie dâ€™intelligence artificielle qui permet dâ€™analyser les textes pour en extraire des indices de personnalitÃ©.</p>
</section>
<section id="un-peu-de-contexte-les-traits-de-personnalitÃ©" class="level2">
<h2 class="anchored" data-anchor-id="un-peu-de-contexte-les-traits-de-personnalitÃ©">Un peu de contexte : les traits de personnalitÃ©</h2>
<p>Dans cet article, les auteurs cherchent Ã  prÃ©dire les traits de personnalitÃ© en fonction du modÃ¨le des <strong>Big Five</strong> ou Â« cinq grands facteurs Â» de la personnalitÃ©. Ce modÃ¨le propose cinq traits fondamentaux :</p>
<ul>
<li><strong>Ouverture Ã  lâ€™expÃ©rience</strong> : imagination, curiositÃ©, crÃ©ativitÃ©</li>
<li><strong>Consciencieux</strong> : organisation, rigueur, discipline</li>
<li><strong>Extraversion</strong> : sociabilitÃ©, expressivitÃ©, dynamisme</li>
<li><strong>AgrÃ©abilitÃ©</strong> : bienveillance, coopÃ©ration, empathie</li>
<li><strong>NÃ©vrosisme</strong> : tendance Ã  lâ€™anxiÃ©tÃ©, la colÃ¨re ou la tristesse</li>
</ul>
<p>Dans la recherche, on tente souvent de relier ces traits Ã  la maniÃ¨re dont une personne parle ou Ã©crit. Par exemple, quelquâ€™un de trÃ¨s extraverti pourrait utiliser plus de mots liÃ©s Ã  lâ€™Ã©motion ou Ã  la premiÃ¨re personne (Â« je Â», Â« moi Â»), tandis quâ€™une personne trÃ¨s nÃ©vrosÃ©e pourrait employer davantage de mots Ã  connotation nÃ©gative.</p>
</section>
<section id="avant-les-transformers-premiÃ¨res-tentatives-danalyse-de-la-personnalitÃ©-Ã -partir-du-texte" class="level2">
<h2 class="anchored" data-anchor-id="avant-les-transformers-premiÃ¨res-tentatives-danalyse-de-la-personnalitÃ©-Ã -partir-du-texte">Avant les transformers : premiÃ¨res tentatives dâ€™analyse de la personnalitÃ© Ã  partir du texte</h2>
<section id="des-approches-symboliques-fondÃ©es-sur-les-mots" class="level3">
<h3 class="anchored" data-anchor-id="des-approches-symboliques-fondÃ©es-sur-les-mots">Des approches symboliques fondÃ©es sur les mots</h3>
<p>Avant lâ€™essor de lâ€™apprentissage profond, les chercheurÂ·es ont tentÃ© dâ€™utiliser des approches plus classiques de lâ€™intelligence artificielle pour analyser le lien entre langage et personnalitÃ©. Ces mÃ©thodes â€” souvent fondÃ©es sur des rÃ¨gles simples ou des statistiques â€” reprÃ©sentent les <strong>premiers pas de lâ€™IA appliquÃ©e Ã  la psychologie du langage</strong>. MÃªme si elles Ã©taient moins performantes que les approches modernes, elles ont posÃ© les bases de ce champ en plein essor : faire parler les textes pour mieux comprendre qui les Ã©crit.</p>
<p>Les premiÃ¨res tentatives pour relier le langage Ã©crit aux traits de personnalitÃ© ont reposÃ© sur des approches dites symboliques ou statistiques. Lâ€™une des plus connues est lâ€™utilisation de <strong>LIWC</strong> (<em>Linguistic Inquiry and Word Count</em>), un outil qui scanne un texte et compte la frÃ©quence de certains types de mots, comme ceux associÃ©s Ã  la colÃ¨re, Ã  la famille, aux Ã©motions positives ou nÃ©gatives. En analysant ces frÃ©quences, les chercheurÂ·es pouvaient Ã©tablir des liens avec des traits de personnalitÃ©. Par exemple, une personne utilisant souvent des mots chargÃ©s dâ€™Ã©motion positive pouvait Ãªtre perÃ§ue comme plus extravertie, alors quâ€™un vocabulaire plus anxiogÃ¨ne Ã©tait frÃ©quemment associÃ© au nÃ©vrosisme.</p>
</section>
<section id="des-modÃ¨les-statistiques-plus-flexibles" class="level3">
<h3 class="anchored" data-anchor-id="des-modÃ¨les-statistiques-plus-flexibles">Des modÃ¨les statistiques plus flexibles</h3>
<p>En parallÃ¨le, des mÃ©thodes plus statistiques se sont dÃ©veloppÃ©es. Des modÃ¨les comme les <strong>forÃªts alÃ©atoires</strong>, les <strong>rÃ©seaux de neurones artificiels simples</strong> ou les <strong>SVM (support vector machines)</strong> ont Ã©tÃ© utilisÃ©s pour prÃ©dire les traits de personnalitÃ© Ã  partir de caractÃ©ristiques linguistiques extraites manuellement. Ces caractÃ©ristiques incluaient, par exemple, le nombre de phrases, la longueur moyenne des mots, la frÃ©quence dâ€™utilisation de certains temps verbaux, ou encore la proportion de pronoms personnels. Ces approches, bien que plus souples que les analyses par mots-clÃ©s, restaient fortement dÃ©pendantes des choix faits par les chercheurs en amont : il fallait dÃ©finir quoi mesurer, et comment.</p>
</section>
<section id="les-limites-de-ces-approches" class="level3">
<h3 class="anchored" data-anchor-id="les-limites-de-ces-approches">Les limites de ces approches</h3>
<p>Cependant, ces premiÃ¨res mÃ©thodes prÃ©sentaient plusieurs limites importantes. Dâ€™abord, elles sâ€™appuyaient sur de nombreuses hypothÃ¨ses implicites : il fallait deviner Ã  lâ€™avance quels Ã©lÃ©ments du langage pourraient Ãªtre liÃ©s Ã  la personnalitÃ©. Ensuite, elles Ã©taient peu sensibles au contexte. Un mot comme Â« froid Â», par exemple, nâ€™aura pas le mÃªme sens selon quâ€™il dÃ©crit la mÃ©tÃ©o ou une relation humaine. Ces modÃ¨les peinaient donc Ã  saisir les subtilitÃ©s du langage naturel. Enfin, leurs performances plafonnaient souvent autour de 65 Ã  70 % de prÃ©cision, ce qui limitait leur utilitÃ© dans des contextes plus complexes ou variÃ©s. Câ€™est prÃ©cisÃ©ment pour dÃ©passer ces limites que les chercheurs se sont tournÃ©s vers des approches plus flexibles et puissantes, comme celles fondÃ©es sur le deep learning. Parmi elles, les modÃ¨les transformers marquent une avancÃ©e majeure.</p>
</section>
</section>
<section id="comprendre-les-transformers" class="level2">
<h2 class="anchored" data-anchor-id="comprendre-les-transformers">Comprendre les transformers</h2>
<p>Avec lâ€™Ã©mergence du deep learning, un nouveau type de modÃ¨le sâ€™est imposÃ© dans le domaine de la comprÃ©hension du langage naturel : le transformer. Introduit en 2017, ce type de modÃ¨le a profondÃ©ment modifiÃ© la maniÃ¨re dont les machines analysent les textes, en offrant une capacitÃ© inÃ©dite Ã  capturer les relations entre les mots, quelle que soit leur position dans la phrase. Contrairement aux anciens modÃ¨les qui lisaient les phrases de faÃ§on linÃ©aire (mot aprÃ¨s mot), les transformers analysent <strong>lâ€™ensemble des mots simultanÃ©ment</strong>.</p>
<p>Pour comprendre cela de faÃ§on simple, imaginez que vous lisiez une lettre. Le mot Â« chaud Â» nâ€™aura pas le mÃªme sens dans Â« une boisson chaude Â» ou dans Â« une ambiance chaude Â». Le sens dÃ©pend des mots qui lâ€™entourent. Les transformers fonctionnent justement sur ce principe : ils accordent Ã  chaque mot une importance diffÃ©rente selon le contexte. Ce mÃ©canisme sâ€™appelle <strong>lâ€™attention</strong>, et câ€™est ce qui permet au modÃ¨le de repÃ©rer quelles parties du texte sont les plus pertinentes pour comprendre un mot donnÃ©.</p>
<p>Dans lâ€™Ã©tude que je prÃ©sente ici, les chercheurÂ·es ont utilisÃ© un modÃ¨le transformer appelÃ© <strong>ELECTRA</strong>. Ce modÃ¨le est un peu particulier : pour sâ€™entraÃ®ner, il joue Ã  un jeu oÃ¹ certains mots du texte sont remplacÃ©s par dâ€™autres, et le modÃ¨le doit deviner quels mots sont â€œfauxâ€. Cela lâ€™oblige Ã  comprendre finement la structure et le sens des phrases. Une fois ce modÃ¨le prÃ©-entraÃ®nÃ©, il peut Ãªtre spÃ©cialisÃ© pour des tÃ¢ches prÃ©cises, comme ici, prÃ©dire les traits de personnalitÃ© Ã  partir de courts textes.</p>
<p>Ce qui rend ELECTRA particuliÃ¨rement intÃ©ressant, câ€™est quâ€™il est plus rapide et plus lÃ©ger que ses prÃ©dÃ©cesseurs, tout en maintenant une trÃ¨s bonne prÃ©cision. De plus, il sâ€™agit dâ€™un modÃ¨le <strong>open-source</strong>, ce qui signifie que toute personne intÃ©ressÃ©e â€“ chercheurÂ·e, praticienÂ·ne ou Ã©tudiantÂ·e â€“ peut librement le consulter, lâ€™utiliser ou lâ€™adapter. Il est accessible sur des plateformes comme Hugging Face, favorisant ainsi la dÃ©mocratisation de lâ€™intelligence artificielle en recherche psychologique. Il est donc adaptÃ© Ã  des tÃ¢ches comme lâ€™analyse psychologique automatisÃ©e, oÃ¹ lâ€™on dispose souvent de quantitÃ©s modÃ©rÃ©es de donnÃ©es et oÃ¹ lâ€™interprÃ©tabilitÃ© est essentielle.</p>
</section>
<section id="comment-lÃ©tude-a-Ã©tÃ©-rÃ©alisÃ©e" class="level2">
<h2 class="anchored" data-anchor-id="comment-lÃ©tude-a-Ã©tÃ©-rÃ©alisÃ©e">Comment lâ€™Ã©tude a Ã©tÃ© rÃ©alisÃ©e</h2>
<p>Les chercheurÂ·es ont utilisÃ© une base de donnÃ©es appelÃ©e <em>Pennebaker and King Essays</em>. On y trouve 2 467 petits textes Ã©crits librement par des adultes, souvent sous forme de rÃ©cits introspectifs ou de rÃ©flexions personnelles. Chacun de ces textes est accompagnÃ© dâ€™un profil de personnalitÃ© Ã©tabli par questionnaire, basÃ© sur le modÃ¨le des Big Five.</p>
<p>Voici comment ils ont procÃ©dÃ© :</p>
<ol type="1">
<li><p><strong>PrÃ©traitement</strong> : Les textes bruts ont dâ€™abord Ã©tÃ© nettoyÃ©s pour les rendre exploitables par le modÃ¨le. Cela inclut la suppression de caractÃ¨res non alphabÃ©tiques, la normalisation des espaces et ponctuations, et la mise en forme uniforme des textes. Un seuil de longueur a Ã©galement Ã©tÃ© fixÃ© pour limiter la variabilitÃ© et standardiser lâ€™entrÃ©e dans le modÃ¨le.</p></li>
<li><p><strong>Augmentation</strong> : Pour compenser la taille relativement modeste du corpus, les chercheurÂ·es ont eu recours Ã  une technique dâ€™augmentation de donnÃ©es. Celle-ci consiste Ã  remplacer certains mots par des synonymes pertinents, extraits de WordNet, de maniÃ¨re alÃ©atoire mais contrÃ´lÃ©e (jusquâ€™Ã  deux remplacements par phrase). Cela permet dâ€™augmenter la diversitÃ© lexicale tout en conservant le sens gÃ©nÃ©ral du texte, ce qui amÃ©liore la robustesse du modÃ¨le lors de la gÃ©nÃ©ralisation Ã  de nouveaux Ã©chantillons.</p></li>
<li><p><strong>EntraÃ®nement</strong> : Cinq modÃ¨les ELECTRA distincts ont Ã©tÃ© entraÃ®nÃ©s, chacun dÃ©diÃ© Ã  la prÃ©diction dâ€™un des cinq traits de personnalitÃ©. En procÃ©dant ainsi, les auteurÂ·es ont Ã©vitÃ© les interfÃ©rences possibles entre traits (par exemple entre agrÃ©abilitÃ© et consciencieux) et ont permis au modÃ¨le dâ€™apprendre des reprÃ©sentations linguistiques spÃ©cifiques Ã  chaque dimension. Lâ€™entraÃ®nement a Ã©tÃ© rÃ©alisÃ© en utilisant un algorithme dâ€™optimisation de type AdamW, avec une stratÃ©gie de rÃ©gularisation pour Ã©viter le surapprentissage.</p></li>
<li><p><strong>Ã‰valuation</strong> : Les performances des modÃ¨les ont Ã©tÃ© mesurÃ©es Ã  lâ€™aide dâ€™un dÃ©coupage standard des donnÃ©es en ensembles dâ€™entraÃ®nement, de validation et de test. Plusieurs mÃ©triques ont Ã©tÃ© utilisÃ©es : prÃ©cision, rappel, score F1 et AUC (aire sous la courbe ROC). Ces indicateurs ont permis de sâ€™assurer que les modÃ¨les ne se contentaient pas de bien performer sur les donnÃ©es apprises, mais Ã©taient capables de gÃ©nÃ©raliser sur de nouveaux textes.</p></li>
</ol>
</section>
<section id="les-rÃ©sultats-en-langage-simple" class="level2">
<h2 class="anchored" data-anchor-id="les-rÃ©sultats-en-langage-simple">Les rÃ©sultats en langage simple</h2>
<p>Les modÃ¨les ont obtenu de <strong>trÃ¨s bons rÃ©sultats</strong>, surpassant les performances dâ€™anciennes approches comme lâ€™analyse lexicale manuelle. Chaque dimension de la personnalitÃ© a Ã©tÃ© considÃ©rÃ©e indÃ©pendamment comme une tÃ¢che de classification binaire (par exemple, distinguer un haut dâ€™un bas niveau dâ€™extraversion), avec une Ã©valuation basÃ©e sur plusieurs mÃ©triques : prÃ©cision, rappel, score F1 et AUC (aire sous la courbe ROC).</p>
<p>Pour <strong>lâ€™extraversion</strong>, le modÃ¨le a obtenu une prÃ©cision de 78 %, avec une AUC remarquable de 0.84. Cela indique quâ€™il distingue bien les personnes extraverties des introverties, en captant des indices comme lâ€™usage frÃ©quent de la premiÃ¨re personne, lâ€™expressivitÃ© et les Ã©motions positives.</p>
<p>Pour <strong>lâ€™ouverture Ã  lâ€™expÃ©rience</strong>, la performance atteint 75 %. Le modÃ¨le semble particuliÃ¨rement sensible Ã  la richesse lexicale, Ã  la prÃ©sence de mots abstraits ou Ã  lâ€™usage de tournures stylistiques variÃ©es, souvent associÃ©es Ã  ce trait.</p>
<p>Concernant <strong>lâ€™agrÃ©abilitÃ©</strong>, le modÃ¨le atteint Ã©galement 74 % de prÃ©cision, avec une AUC solide. Il semble repÃ©rer des expressions de politesse, des tournures conciliantes et un ton globalement prosocial.</p>
<p>Pour <strong>le nÃ©vrosisme</strong>, le score de 74 % reflÃ¨te une bonne capacitÃ© Ã  dÃ©tecter les marqueurs de tension Ã©motionnelle, comme les mots associÃ©s Ã  lâ€™inquiÃ©tude, au doute ou Ã  la frustration.</p>
<p>Enfin, <strong>la conscienciositÃ©</strong> est le trait oÃ¹ le modÃ¨le obtient la prÃ©cision la plus faible (72 %), mais tout de mÃªme supÃ©rieure aux standards classiques. Ce trait semble plus difficile Ã  infÃ©rer Ã  partir de textes courts, car il repose sur des indices moins saillants, comme la structure syntaxique, la rÃ©gularitÃ© ou lâ€™organisation du discours.</p>
<p>Ces rÃ©sultats sont dâ€™autant plus notables que les textes analysÃ©s sont brefs, spontanÃ©s, et Ã©crits dans un cadre non contraint. La capacitÃ© du modÃ¨le Ã  extraire de tels signaux Ã  partir dâ€™un matÃ©riau aussi variable illustre la puissance de cette approche.</p>
</section>
<section id="pourquoi-cest-prometteur-pour-la-psychologie" class="level2">
<h2 class="anchored" data-anchor-id="pourquoi-cest-prometteur-pour-la-psychologie">Pourquoi câ€™est prometteur pour la psychologie</h2>
<section id="un-outil-prÃ©cieux-pour-la-recherche" class="level3">
<h3 class="anchored" data-anchor-id="un-outil-prÃ©cieux-pour-la-recherche">1. Un outil prÃ©cieux pour la recherche</h3>
<p>Les chercheurÂ·es en psychologie manipulent souvent de grandes quantitÃ©s de textes â€” que ce soit des rÃ©ponses ouvertes Ã  des questionnaires, des journaux personnels, ou des messages sur des forums en ligne. Analyser tout cela manuellement peut prendre des semaines. GrÃ¢ce Ã  des modÃ¨les comme ELECTRA, on peut <strong>obtenir une premiÃ¨re lecture automatisÃ©e</strong> de ces textes : le modÃ¨le identifie les tournures, les mots ou les styles dâ€™Ã©criture qui pourraient Ãªtre liÃ©s Ã  certains traits de personnalitÃ©. Cela permet de <strong>gagner du temps</strong>, dâ€™Ã©largir le champ des Ã©tudes, et de formuler de nouvelles hypothÃ¨ses Ã  partir de donnÃ©es linguistiques quâ€™on aurait autrement nÃ©gligÃ©es.</p>
</section>
<section id="un-soutien-pour-les-pratiques-cliniques-et-communautaires" class="level3">
<h3 class="anchored" data-anchor-id="un-soutien-pour-les-pratiques-cliniques-et-communautaires">2. Un soutien pour les pratiques cliniques et communautaires</h3>
<p>Dans des contextes comme la clinique, lâ€™intervention communautaire ou mÃªme lâ€™Ã©ducation, il est souvent utile de <strong>comprendre rapidement le vÃ©cu ou le profil dâ€™une personne</strong>, surtout quand le contact est bref ou se fait en ligne. Un outil comme ELECTRA pourrait, par exemple, analyser de maniÃ¨re discrÃ¨te les premiÃ¨res rÃ©ponses Ã©crites dâ€™une personne sur une plateforme de soutien ou dans un formulaire dâ€™accueil. Il pourrait ainsi <strong>suggÃ©rer certains indicateurs linguistiques</strong> liÃ©s Ã  lâ€™anxiÃ©tÃ©, Ã  lâ€™agrÃ©abilitÃ© ou Ã  lâ€™ouverture dâ€™esprit, ce qui permettrait aux intervenantÂ·es dâ€™adapter leur approche. Cela ne remplace pas le jugement professionnel, mais cela peut <strong>offrir un regard complÃ©mentaire</strong>, plus subtil, pour guider la relation dâ€™aide.</p>
</section>
<section id="vers-des-technologies-plus-sensibles-aux-personnes" class="level3">
<h3 class="anchored" data-anchor-id="vers-des-technologies-plus-sensibles-aux-personnes">3. Vers des technologies plus sensibles aux personnes</h3>
<p>Cette technologie pourrait aussi transformer <strong>les interfaces numÃ©riques elles-mÃªmes</strong>. Imaginez un agent conversationnel (chatbot) qui <strong>ajuste son style de rÃ©ponse</strong> selon la personnalitÃ© perÃ§ue de la personne avec qui il Ã©change : plus chaleureux, plus structurÃ©, plus crÃ©atifâ€¦ Un tel ajustement pourrait rendre les interactions plus naturelles et plus humaines. Câ€™est une faÃ§on de concevoir lâ€™IA non pas comme un outil froid et distant, mais comme un <strong>alliÃ© dans la crÃ©ation de liens</strong>, capable de mieux comprendre et de mieux sâ€™adapter aux personnes.</p>
</section>
</section>
<section id="et-les-limites" class="level2">
<h2 class="anchored" data-anchor-id="et-les-limites">Et les limites?</h2>
<p>Ã‰videmment, tout nâ€™est pas parfait :</p>
<ul>
<li>Lâ€™algorithme fonctionne surtout sur <strong>des textes en anglais</strong>, Ã©crits par une population assez homogÃ¨ne.</li>
<li>Il ne prend en compte <strong>que le texte</strong>, pas le ton de la voix, le contexte, ni les Ã©motions ressenties.</li>
<li>Le modÃ¨le peut <strong>surapprendre</strong> Ã  ses exemples, ce qui limite parfois sa gÃ©nÃ©ralisation.</li>
</ul>
<p>Mais ces dÃ©fis sont connus, et les auteurÂ·es proposent plusieurs pistes pour y remÃ©dier (donnÃ©es plus variÃ©es, donnÃ©es multimodales, etc.).</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>Cette Ã©tude nous montre que des modÃ¨les comme ELECTRA peuvent <strong>apprendre Ã  â€œread between the linesâ€</strong>, et identifier des <strong>indices subtils de la personnalitÃ©</strong> dans les textes. Cela ne remplace pas une Ã©valuation clinique, bien sÃ»r, mais cela ouvre la voie Ã  des outils hybrides, oÃ¹ <strong>lâ€™IA soutient lâ€™humain</strong>.</p>
<p>Je continuerai dâ€™explorer ces liens entre langage, psychologie et IA dans ce blogue. Nâ€™hÃ©sitez pas Ã  mâ€™Ã©crire si vous souhaitez que jâ€™aborde un sujet en particulier!</p>
<p>Lâ€™article complet est disponible ici : <strong>Saberi, H., Ghofrani, S., &amp; Ravanmehr, R. (2025)</strong>. <em>Personality Recognition Using Transformer Model: A Study on the Big Five Traits</em>. IEEE ICWR. ğŸ”— <a href="https://ieeexplore.ieee.org/document/11006181">AccÃ¨s via IEEE Xplore</a></p>


</section>

 ]]></description>
  <category>MÃ©thodologie augmentÃ©e par lâ€™IA</category>
  <guid>https://benoitplante.github.io/blogue/posts/2025-05-29-personnalite-transformer/</guid>
  <pubDate>Mon, 26 May 2025 04:00:00 GMT</pubDate>
  <media:content url="https://benoitplante.github.io/blogue/posts/2025-05-29-personnalite-transformer/banner_article_electra.png" medium="image" type="image/png" height="96" width="144"/>
</item>
<item>
  <title>Quand une IA devient co-chercheuse : rÃ©flexions autour de Robin</title>
  <dc:creator>Benoit Plante</dc:creator>
  <link>https://benoitplante.github.io/blogue/posts/2025-05-21-ai-robin/</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://benoitplante.github.io/blogue/posts/2025-05-21-ai-robin/banner.png" class="img-fluid figure-img"></p>
<figcaption>GÃ©nÃ©rÃ©e par ChatGPT</figcaption>
</figure>
</div>
<section id="une-dÃ©couverte-marquante" class="level2">
<h2 class="anchored" data-anchor-id="une-dÃ©couverte-marquante">Une dÃ©couverte marquante</h2>
<p>Je suis tombÃ© rÃ©cemment sur une annonce qui mâ€™a Ã  la fois fascinÃ© et interpellÃ© : le laboratoire <a href="https://www.futurehouse.org">Future House</a>, un groupe de recherche basÃ© Ã  San Francisco qui explore les frontiÃ¨res de la dÃ©couverte scientifique automatisÃ©e, a prÃ©sentÃ© <em>Robin</em>, une plateforme dâ€™IA capable de rÃ©aliser plusieurs Ã©tapes clÃ©s du travail scientifique. Elle peut lire des articles, formuler des hypothÃ¨ses, proposer des expÃ©riences, analyser les rÃ©sultats et mÃªme suggÃ©rer des pistes de recherche Ã  explorer ensuite. Et tout cela se fait Ã  lâ€™aide dâ€™un systÃ¨me dit Â« multi-agent Â», avec lâ€™intervention de chercheuses et chercheurs seulement pour les Ã©tapes en laboratoire.</p>
<p>Un systÃ¨me multi-agent, câ€™est un ensemble de petits programmes spÃ©cialisÃ©s, appelÃ©s agents, qui collaborent pour accomplir des tÃ¢ches complexes. Chacun a un rÃ´le bien prÃ©cis : certains cherchent dans la littÃ©rature scientifique, dâ€™autres analysent les donnÃ©es dâ€™expÃ©riences, dâ€™autres encore comparent diffÃ©rentes pistes pour sÃ©lectionner les plus prometteuses. Dans le cas de Robin, ces agents sâ€™appellent Crow, Falcon et Finch, et ils sont conÃ§us pour se complÃ©ter comme une Ã©quipe de recherche virtuelle.</p>
<p>Le preprint associÃ© au projet, intitulÃ© <em>Robin: A Multi-Agent System for Automating Scientific Discovery</em> (Ghareeb et al., 2025), prÃ©sente une dÃ©monstration concrÃ¨te dans le domaine biomÃ©dical : Robin a permis dâ€™identifier un nouveau candidat thÃ©rapeutique pour traiter la dÃ©gÃ©nÃ©rescence maculaire liÃ©e Ã  lâ€™Ã¢ge (forme sÃ¨che), en proposant une piste qui nâ€™avait jamais Ã©tÃ© explorÃ©e auparavant â€” le ripasudil, un mÃ©dicament dÃ©jÃ  utilisÃ© pour dâ€™autres troubles oculaires. Tout le raisonnement scientifique, les figures et les analyses prÃ©sentÃ©s dans lâ€™article ont Ã©tÃ© gÃ©nÃ©rÃ©s par Robin.</p>
</section>
<section id="quelles-implications-pour-la-psychologie" class="level2">
<h2 class="anchored" data-anchor-id="quelles-implications-pour-la-psychologie">Quelles implications pour la psychologie?</h2>
<p>Cette avancÃ©e mâ€™amÃ¨ne Ã  me poser des questions sur ce que cela signifie pour des disciplines comme la psychologie, oÃ¹ les donnÃ©es sont souvent plus complexes, nuancÃ©es, et ancrÃ©es dans des contextes humains.</p>
<p>Aujourdâ€™hui dÃ©jÃ , je considÃ¨re que certains outils dâ€™IA agissent comme de vÃ©ritables partenaires dans nos dÃ©marches scientifiques. Je les utilise pour synthÃ©tiser de la littÃ©rature, organiser des corpus de donnÃ©es, ou encore proposer des structures dâ€™analyse. Nous sommes donc dÃ©jÃ  entrÃ©s dans une Ã¨re de recherche assistÃ©e. La nouveautÃ© avec Robin, câ€™est que lâ€™on entrevoit maintenant la possibilitÃ© dâ€™un cycle de recherche entiÃ¨rement automatisÃ© â€” du moins dans certains contextes bien circonscrits.</p>
<p>Par exemple, on peut imaginer des systÃ¨mes capables dâ€™explorer des bases de donnÃ©es ouvertes, de formuler des hypothÃ¨ses Ã  partir de connaissances publiÃ©es, puis dâ€™analyser des donnÃ©es accessibles publiquement pour confirmer ou rejeter ces hypothÃ¨ses. Dans le domaine de la psychologie, cela pourrait se faire avec des jeux de donnÃ©es longitudinaux disponibles en libre accÃ¨s, en lien avec le dÃ©veloppement de lâ€™enfant, la santÃ© mentale ou les dÃ©terminants sociaux.</p>
<p>Un systÃ¨me comme Robin pourrait thÃ©oriquement formuler des hypothÃ¨ses Ã  partir de ces corpus, effectuer des analyses exploratoires, et suggÃ©rer de nouvelles directions de recherche, le tout sans intervention humaine directe â€” tout en permettant une validation et une interprÃ©tation ensuite par des Ã©quipes humaines. Cela ne remplacerait pas la recherche participative ou contextuelle, mais cela permettrait de gÃ©nÃ©rer de nouvelles connaissances en parallÃ¨le, de faÃ§on continue.</p>
</section>
<section id="une-transformation-Ã -suivre-de-prÃ¨s" class="level2">
<h2 class="anchored" data-anchor-id="une-transformation-Ã -suivre-de-prÃ¨s">Une transformation Ã  suivre de prÃ¨s</h2>
<p>Je vais suivre de prÃ¨s les dÃ©veloppements autour de Robin et des autres projets similaires. Ils ouvrent une rÃ©flexion profonde sur notre maniÃ¨re de faire de la recherche, sur notre rapport Ã  la connaissance, et sur la faÃ§on dont lâ€™IA pourrait enrichir, sans remplacer, notre comprÃ©hension du monde. Ces technologies ne nous invitent pas seulement Ã  revoir nos outils, mais Ã  repenser nos mÃ©thodologies, nos collaborations et nos modÃ¨les de diffusion du savoir. Il se pourrait quâ€™une partie de la science de demain ne soit pas Ã©crite par des humains, mais validÃ©e, partagÃ©e et enrichie par eux. Câ€™est une perspective Ã  la fois stimulante et exigeante, qui demande une vigilance Ã©thique et une ouverture intellectuelle constante.</p>
<p><strong>RÃ©fÃ©rence :</strong><br>
Ghareeb, A. E., Chang, B., Mitchener, L., Yiu, A., Szostkiewicz, C. J., Laurent, J. M., â€¦ &amp; Rodriques, S. G. (2025). <em>Robin: A multi-agent system for automating scientific discovery</em>. arXiv preprint arXiv:2505.13400. <a href="https://arxiv.org/abs/2505.13400">https://arxiv.org/abs/2505.13400</a></p>
<hr>
<!--Include social share buttons-->
<!-- 
AddToAny check more: https://www.addtoany.com/buttons/for/website 
Using includes will make edits easier, will only need to add or remove button here if needed.
https://quarto.org/docs/authoring/includes.html
-->
<div class="a2a_kit a2a_kit_size_32 a2a_default_style">
<p><a class="a2a_dd" href="https://www.addtoany.com/share"></a> <a class="a2a_button_linkedin"></a> <a class="a2a_button_bluesky"></a> <a class="a2a_button_facebook"></a> <a class="a2a_button_copy_link"></a> <a class="a2a_button_email"></a></p>
</div>
<script async="" src="https://static.addtoany.com/menu/page.js"></script>


</section>

 ]]></description>
  <category>MÃ©thodologie augmentÃ©e par lâ€™IA</category>
  <guid>https://benoitplante.github.io/blogue/posts/2025-05-21-ai-robin/</guid>
  <pubDate>Wed, 21 May 2025 04:00:00 GMT</pubDate>
  <media:content url="https://benoitplante.github.io/blogue/posts/2025-05-21-ai-robin/banner.png" medium="image" type="image/png" height="96" width="144"/>
</item>
</channel>
</rss>
