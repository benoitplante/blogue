git add --all
git init
# Chargement des librairies pour le nettoyage et la préparation
library(tidyverse)
library(tidytext)
library(text)
# 1. Nettoyage des mots-clés
df <- df %>%
mutate(mots_cles = mots_cles %>%
str_to_lower() %>%
str_replace_all("\\s+", " ") %>%
str_trim())
# Chargement des données exportées
df <- read_csv("database/df_projets_familia.csv.csv")
# Chargement des données exportées
df <- read_csv("database/df_projets_familia.csv.csv")
# Chargement des données exportées
df <- read_csv("database/df_projets_familia.csv")
setwd("C:/Users/planteb/Desktop/Projet R/familia")
# Chargement des données exportées
df <- read_csv("database/df_projets_familia.csv")
# 3. Analyse des données manquantes
missing_summary <- df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(everything(), names_to = "variable", values_to = "proportion_na") %>%
arrange(desc(proportion_na))
# 1. Nettoyage des mots-clés
df <- df %>%
mutate(mots_cles = mots_cles %>%
str_to_lower() %>%
str_replace_all("\\s+", " ") %>%
str_trim())
# 2. Nettoyage des auteurs
df <- df %>%
mutate(auteurs = auteurs %>%
str_replace_all("\\s+", " ") %>%
str_to_title() %>%
str_trim())
# 4. Normalisation des dates
df <- df %>%
mutate(annee_extrait = str_extract(annee, "\\d{4}"),
annee_extrait = as.integer(annee_extrait))
# 5. Standardisation des types de documents
df <- df %>%
mutate(type_doc_std = case_when(
str_detect(type_doc, regex("th[èe]se|mémoire", ignore_case = TRUE)) ~ "Thèse/Mémoire",
str_detect(type_doc, regex("rapport", ignore_case = TRUE)) ~ "Rapport",
str_detect(type_doc, regex("article", ignore_case = TRUE)) ~ "Article",
TRUE ~ "Autre"
))
# 6. Nettoyage des titres
df <- df %>%
mutate(titre_clean = titre %>%
str_to_lower() %>%
str_replace_all("[\"'’]", "") %>%
str_squish())
# 7. Nettoyage HTML dans les champs de sommaire
df <- df %>%
mutate(sommaire_clean = map_chr(sommaire, ~{
if (is.na(.x) || .x == "") return(NA_character_)
as.character(xml2::xml_text(xml2::read_html(paste0("<body>", .x, "</body>"))))
}))
df <- df %>%
mutate(
methode_instruments = str_extract(sommaire_clean, regex("Instruments\\s*:\\s*(.*?)\\s*Type\\s*de\\s*traitement", ignore_case = TRUE)) %>%
str_remove_all(regex("Instruments\\s*:\\s*|Type\\s*de\\s*traitement", ignore_case = TRUE)) %>%
str_trim(),
methode_analyse = str_extract(sommaire_clean, regex("Type de traitement des donn[ée]es\\s*:\\s*([^\\n\\.]*)", ignore_case = TRUE, multiline = TRUE)) %>%
str_replace(regex("Type de traitement des donn[ée]es\\s*:\\s*", ignore_case = TRUE), "") %>%
str_remove("\\s*3\\s*$")
)
View(df)
df <- df %>%
mutate(thematiques_clean = thematiques %>%
str_to_lower() %>%
str_replace_all("[\"'’]", "") %>%
str_squish())
# 9. Sélection des colonnes pertinentes pour la suite
df <- df %>%
select(titre_clean, auteurs, thematiques_clean, annee_extrait, type_doc_std, mots_cles, methode_instruments, methode_analyse)
View(df)
df <- df %>%
mutate(thematiques_clean = thematiques %>%
str_to_lower() %>%
str_replace_all("[\"'’]", "") %>%
str_squish())
# Chargement des données exportées
df <- read_csv("database/df_projets_familia.csv")
# 3. Analyse des données manquantes
missing_summary <- df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(everything(), names_to = "variable", values_to = "proportion_na") %>%
arrange(desc(proportion_na))
# 1. Nettoyage des mots-clés
df <- df %>%
mutate(mots_cles = mots_cles %>%
str_to_lower() %>%
str_replace_all("\\s+", " ") %>%
str_trim())
# 2. Nettoyage des auteurs
df <- df %>%
mutate(auteurs = auteurs %>%
str_replace_all("\\s+", " ") %>%
str_to_title() %>%
str_trim())
# 4. Normalisation des dates
df <- df %>%
mutate(annee_extrait = str_extract(annee, "\\d{4}"),
annee_extrait = as.integer(annee_extrait))
# 5. Standardisation des types de documents
df <- df %>%
mutate(type_doc_std = case_when(
str_detect(type_doc, regex("th[èe]se|mémoire", ignore_case = TRUE)) ~ "Thèse/Mémoire",
str_detect(type_doc, regex("rapport", ignore_case = TRUE)) ~ "Rapport",
str_detect(type_doc, regex("article", ignore_case = TRUE)) ~ "Article",
TRUE ~ "Autre"
))
# 6. Nettoyage des titres
df <- df %>%
mutate(titre_clean = titre %>%
str_to_lower() %>%
str_replace_all("[\"'’]", "") %>%
str_squish())
df <- df %>%
mutate(thematiques_clean = thematiques %>%
str_to_lower() %>%
str_replace_all("[\"'’]", "") %>%
str_squish())
# 8. Nettoyage HTML dans les champs de sommaire
df <- df %>%
mutate(sommaire_clean = map_chr(sommaire, ~{
if (is.na(.x) || .x == "") return(NA_character_)
as.character(xml2::xml_text(xml2::read_html(paste0("<body>", .x, "</body>"))))
}))
df <- df %>%
mutate(
methode_instruments = str_extract(sommaire_clean, regex("Instruments\\s*:\\s*(.*?)\\s*Type\\s*de\\s*traitement", ignore_case = TRUE)) %>%
str_remove_all(regex("Instruments\\s*:\\s*|Type\\s*de\\s*traitement", ignore_case = TRUE)) %>%
str_trim(),
methode_analyse = str_extract(sommaire_clean, regex("Type de traitement des donn[ée]es\\s*:\\s*([^\\n\\.]*)", ignore_case = TRUE, multiline = TRUE)) %>%
str_replace(regex("Type de traitement des donn[ée]es\\s*:\\s*", ignore_case = TRUE), "") %>%
str_remove("\\s*3\\s*$")
)
# 9. Sélection des colonnes pertinentes pour la suite
df <- df %>%
select(titre_clean, auteurs, thematiques_clean, annee_extrait, type_doc_std, mots_cles, methode_instruments, methode_analyse)
View(df)
# Chargement des données exportées
df <- read_csv("database/df_projets_familia.csv")
# 3. Analyse des données manquantes
missing_summary <- df %>%
summarise(across(everything(), ~mean(is.na(.)))) %>%
pivot_longer(everything(), names_to = "variable", values_to = "proportion_na") %>%
arrange(desc(proportion_na))
# 1. Nettoyage des mots-clés
df <- df %>%
mutate(mots_cles = mots_cles %>%
str_to_lower() %>%
str_replace_all("\\s+", " ") %>%
str_trim())
# 2. Nettoyage des auteurs
df <- df %>%
mutate(auteurs = auteurs %>%
str_replace_all("\\s+", " ") %>%
str_to_title() %>%
str_trim())
# 4. Normalisation des dates
df <- df %>%
mutate(annee_extrait = str_extract(annee, "\\d{4}"),
annee_extrait = as.integer(annee_extrait))
# 5. Standardisation des types de documents
df <- df %>%
mutate(type_doc_std = case_when(
str_detect(type_doc, regex("th[èe]se|mémoire", ignore_case = TRUE)) ~ "Thèse/Mémoire",
str_detect(type_doc, regex("rapport", ignore_case = TRUE)) ~ "Rapport",
str_detect(type_doc, regex("article", ignore_case = TRUE)) ~ "Article",
TRUE ~ "Autre"
))
# 6. Nettoyage des titres
df <- df %>%
mutate(titre_clean = titre %>%
str_to_lower() %>%
str_replace_all("[\"'’]", "") %>%
str_squish())
df <- df %>%
mutate(thematiques_clean = thematiques %>%
str_to_lower() %>%
str_replace_all("[\"'’]", "") %>%
str_replace("/+$", "") %>%    # <-- supprime les / finaux
str_squish())
# 8. Nettoyage HTML dans les champs de sommaire
df <- df %>%
mutate(sommaire_clean = map_chr(sommaire, ~{
if (is.na(.x) || .x == "") return(NA_character_)
as.character(xml2::xml_text(xml2::read_html(paste0("<body>", .x, "</body>"))))
}))
df <- df %>%
mutate(
methode_instruments = str_extract(sommaire_clean, regex("Instruments\\s*:\\s*(.*?)\\s*Type\\s*de\\s*traitement", ignore_case = TRUE)) %>%
str_remove_all(regex("Instruments\\s*:\\s*|Type\\s*de\\s*traitement", ignore_case = TRUE)) %>%
str_trim(),
methode_analyse = str_extract(sommaire_clean, regex("Type de traitement des donn[ée]es\\s*:\\s*([^\\n\\.]*)", ignore_case = TRUE, multiline = TRUE)) %>%
str_replace(regex("Type de traitement des donn[ée]es\\s*:\\s*", ignore_case = TRUE), "") %>%
str_remove("\\s*3\\s*$")
)
# 9. Sélection des colonnes pertinentes pour la suite
df <- df %>%
select(titre_clean, auteurs, thematiques_clean, annee_extrait, type_doc_std, mots_cles, methode_instruments, methode_analyse)
View(df)
write.csv(df, "database/df_projets_familia_finale.csv", row.names = FALSE)
# Importer les données
df <- read_csv("https://raw.githubusercontent.com/benoitplante/familia/main/database/df_projets_familia_finale.csv")
# Charger les librairies nécessaires
library(tidyverse)
# Importer les données
df <- read_csv("https://raw.githubusercontent.com/benoitplante/familia/main/database/df_projets_familia_finale.csv")
# Filtrer les données avec thématiques valides
df_thematiques <- df_filtered %>%
filter(!is.na(thematiques_clean))
# 1. Tableau du nombre d’articles par thématique et par année
table_thematiques <- df_thematiques %>%
count(annee_extrait, thematiques_clean, name = "n_articles") %>%
pivot_wider(names_from = thematiques_clean, values_from = n_articles, values_fill = 0)
# Filtrer les données avec thématiques valides
df_thematiques <- df_filtered %>%
filter(!is.na(thematiques_clean))
View(df)
library(tidyverse)
library(ggplot2)
df_filtered <- df %>%
filter(annee_extrait >= 2000 & annee_extrait <= 2023)
articles_per_year <- df_filtered %>%
count(annee_extrait, name = "n_articles")
lm_model <- lm(n_articles ~ annee_extrait, data = articles_per_year)
poisson_model <- glm(n_articles ~ annee_extrait, family = poisson(), data = articles_per_year)
articles_per_year %>%
ggplot(aes(x = annee_extrait, y = n_articles)) +
geom_point(color = "blue") +
geom_line(aes(y = pred_lm), color = "red", linetype = "dashed") +
geom_line(aes(y = pred_poisson), color = "green") +
labs(
title = "Évolution du nombre d'articles (2000–2023)",
subtitle = "Régression linéaire (rouge pointillé) vs Poisson (vert)",
x = "Année",
y = "Nombre d'articles"
) +
theme_minimal()
articles_per_year %>%
ggplot(aes(x = annee_extrait, y = n_articles)) +
geom_point(color = "blue") +
geom_line(aes(y = pred_lm), color = "red", linetype = "dashed") +
geom_line(aes(y = pred_poisson), color = "green") +
labs(
title = "Évolution du nombre d'articles (2000–2023)",
subtitle = "Régression linéaire (rouge pointillé) vs Poisson (vert)",
x = "Année",
y = "Nombre d'articles"
) +
theme_minimal()
df_thematiques <- df_filtered %>%
filter(!is.na(thematiques_clean))
df_prop <- df_thematiques %>%
count(annee_extrait, thematiques_clean, name = "n") %>%
group_by(annee_extrait) %>%
mutate(total = sum(n),
proportion = n / total) %>%
ungroup()
df_prop %>%
ggplot(aes(x = annee_extrait, y = proportion, color = thematiques_clean)) +
geom_line() +
geom_point() +
labs(title = "Proportion relative des thématiques (2000–2023)",
x = "Année", y = "Proportion", color = "Thématique") +
theme_minimal()
df_prop <- df_prop %>%
mutate(year_centered = annee_extrait - mean(annee_extrait))
results <- df_prop %>%
group_by(thematiques_clean) %>%
do(tidy(glm(cbind(n, total - n) ~ year_centered,
data = ., family = "binomial"))) %>%
filter(term == "year_centered") %>%
mutate(tendance = if_else(estimate > 0, "hausse", "baisse")) %>%
arrange(p.value)
results <- df_prop %>%
group_by(thematiques_clean) %>%
do(tidy(glm(cbind(n, total - n) ~ year_centered,
data = ., family = "binomial"))) %>%
filter(term == "year_centered") %>%
mutate(tendance = if_else(estimate > 0, "hausse", "baisse")) %>%
arrange(p.value)
results <- df_prop %>%
group_by(thematiques_clean) %>%
do(broom::tidy(glm(cbind(n, total - n) ~ year_centered,
data = ., family = "binomial"))) %>%
filter(term == "year_centered") %>%
mutate(tendance = if_else(estimate > 0, "hausse", "baisse")) %>%
arrange(p.value)
View(results)
