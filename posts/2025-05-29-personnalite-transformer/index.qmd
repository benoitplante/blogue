---
title: "ReconnaÃ®tre la personnalitÃ© Ã  partir de textes? Une Ã©tude prometteuse avec les modÃ¨les transformers"
categories: ["MÃ©thodologie augmentÃ©e par lâ€™IA"]
date: 2025-05-26
image: banner_article_electra.png
format:
  html:
    title-block-banner: true
    css: styles.css
---

![GÃ©nÃ©rÃ©e par ChatGPT](banner_article_electra.png)

## Introduction

Peut-on prÃ©dire les traits de personnalitÃ© dâ€™une personne simplement Ã  partir dâ€™un texte quâ€™elle a Ã©crit? Cette question, qui pourrait sembler tirÃ©e dâ€™un film de science-fiction, est aujourdâ€™hui au cÅ“ur de recherches sÃ©rieuses en psychologie computationnelle. Jâ€™ai rÃ©cemment lu une Ã©tude fascinante prÃ©sentÃ©e Ã  la confÃ©rence IEEE ICWR 2025, qui explore cette idÃ©e Ã  lâ€™aide dâ€™un modÃ¨le dâ€™intelligence artificielle appelÃ© ELECTRA, une version moderne des modÃ¨les transformers.

Dans ce billet, je prÃ©sente lâ€™article en question ainsi que la technologie dâ€™intelligence artificielle qui permet dâ€™analyser les textes pour en extraire des indices de personnalitÃ©.

## Un peu de contexte : les traits de personnalitÃ©

Dans cet article, les auteurs cherchent Ã  prÃ©dire les traits de personnalitÃ© en fonction du modÃ¨le des Big Five ou Â« cinq grands facteurs Â» de la personnalitÃ©. Ce modÃ¨le propose cinq traits fondamentaux :

-   **Ouverture Ã  lâ€™expÃ©rience** : imagination, curiositÃ©, crÃ©ativitÃ©
-   **Consciencieux** : organisation, rigueur, discipline
-   **Extraversion** : sociabilitÃ©, expressivitÃ©, dynamisme
-   **AgrÃ©abilitÃ©** : bienveillance, coopÃ©ration, empathie
-   **NÃ©vrosisme** : tendance Ã  lâ€™anxiÃ©tÃ©, la colÃ¨re ou la tristesse

Dans la recherche, on tente souvent de relier ces traits Ã  la maniÃ¨re dont une personne parle ou Ã©crit. Par exemple, quelquâ€™un de trÃ¨s extraverti pourrait utiliser plus de mots liÃ©s Ã  lâ€™Ã©motion ou Ã  la premiÃ¨re personne (Â« je Â», Â« moi Â»), tandis quâ€™une personne trÃ¨s nÃ©vrosÃ©e pourrait employer davantage de mots Ã  connotation nÃ©gative.

## Avant les transformers : premiÃ¨res tentatives dâ€™analyse de la personnalitÃ© Ã  partir du texte

### Des approches symboliques fondÃ©es sur les mots

Avant lâ€™essor de lâ€™apprentissage profond, les chercheurÂ·es ont tentÃ© dâ€™utiliser des approches plus classiques de lâ€™intelligence artificielle pour analyser le lien entre langage et personnalitÃ©. Ces mÃ©thodes â€” souvent fondÃ©es sur des rÃ¨gles simples ou des statistiques â€” reprÃ©sentent les premiers pas de lâ€™IA appliquÃ©e Ã  la psychologie du langage. MÃªme si elles Ã©taient moins performantes que les approches modernes, elles ont posÃ© les bases de ce champ en plein essor : faire parler les textes pour mieux comprendre qui les Ã©crit.

Les premiÃ¨res tentatives pour relier le langage Ã©crit aux traits de personnalitÃ© ont reposÃ© sur des approches dites symboliques ou statistiques. Lâ€™une des plus connues est lâ€™utilisation de LIWC (Linguistic Inquiry and Word Count), un outil qui scanne un texte et compte la frÃ©quence de certains types de mots, comme ceux associÃ©s Ã  la colÃ¨re, Ã  la famille, aux Ã©motions positives ou nÃ©gatives. En analysant ces frÃ©quences, les chercheurÂ·es pouvaient Ã©tablir des liens avec des traits de personnalitÃ©. Par exemple, une personne utilisant souvent des mots chargÃ©s dâ€™Ã©motion positive pouvait Ãªtre perÃ§ue comme plus extravertie, alors quâ€™un vocabulaire plus anxiogÃ¨ne Ã©tait frÃ©quemment associÃ© au nÃ©vrosisme.

### Des modÃ¨les statistiques plus flexibles

En parallÃ¨le, des mÃ©thodes plus statistiques se sont dÃ©veloppÃ©es. Des modÃ¨les comme les forÃªts alÃ©atoires, les rÃ©seaux de neurones artificiels simples ou les SVM (support vector machines) ont Ã©tÃ© utilisÃ©s pour prÃ©dire les traits de personnalitÃ© Ã  partir de caractÃ©ristiques linguistiques extraites manuellement. Ces caractÃ©ristiques incluaient, par exemple, le nombre de phrases, la longueur moyenne des mots, la frÃ©quence dâ€™utilisation de certains temps verbaux, ou encore la proportion de pronoms personnels. Ces approches, bien que plus souples que les analyses par mots-clÃ©s, restaient fortement dÃ©pendantes des choix faits par les chercheurs en amont : il fallait dÃ©finir quoi mesurer, et comment.

### Les limites de ces approches

Cependant, ces premiÃ¨res mÃ©thodes prÃ©sentaient plusieurs limites importantes. Dâ€™abord, elles sâ€™appuyaient sur de nombreuses hypothÃ¨ses implicites : il fallait deviner Ã  lâ€™avance quels Ã©lÃ©ments du langage pourraient Ãªtre liÃ©s Ã  la personnalitÃ©. Ensuite, elles Ã©taient peu sensibles au contexte. Un mot comme Â« froid Â», par exemple, nâ€™aura pas le mÃªme sens selon quâ€™il dÃ©crit la mÃ©tÃ©o ou une relation humaine. Ces modÃ¨les peinaient donc Ã  saisir les subtilitÃ©s du langage naturel. Enfin, leurs performances plafonnaient souvent autour de 65 Ã  70 % de prÃ©cision, ce qui limitait leur utilitÃ© dans des contextes plus complexes ou variÃ©s. Câ€™est prÃ©cisÃ©ment pour dÃ©passer ces limites que les chercheurs se sont tournÃ©s vers des approches plus flexibles et puissantes, comme celles fondÃ©es sur le deep learning. Parmi elles, les modÃ¨les transformers marquent une avancÃ©e majeure.

## Comprendre les modÃ¨les transformers

Avec lâ€™Ã©mergence du deep learning, un nouveau type de modÃ¨le sâ€™est imposÃ© dans le domaine de la comprÃ©hension du langage naturel : le transformer. Introduit en 2017, ce type de modÃ¨le a profondÃ©ment modifiÃ© la maniÃ¨re dont les machines analysent les textes, en offrant une capacitÃ© inÃ©dite Ã  capturer les relations entre les mots, quelle que soit leur position dans la phrase. Contrairement aux anciens modÃ¨les qui lisaient les phrases de faÃ§on linÃ©aire (mot aprÃ¨s mot), les transformers analysent lâ€™ensemble des mots simultanÃ©ment.

Pour comprendre cela de faÃ§on simple, imaginez que vous lisiez une lettre. Le mot Â« chaud Â» nâ€™aura pas le mÃªme sens dans Â« une boisson chaude Â» ou dans Â« une ambiance chaude Â». Le sens dÃ©pend des mots qui lâ€™entourent. Les transformers fonctionnent justement sur ce principe : ils accordent Ã  chaque mot une importance diffÃ©rente selon le contexte. Ce mÃ©canisme sâ€™appelle â€™attention, et câ€™est ce qui permet au modÃ¨le de repÃ©rer quelles parties du texte sont les plus pertinentes pour comprendre un mot donnÃ©.

Dans lâ€™Ã©tude que je prÃ©sente ici, les chercheurÂ·es ont utilisÃ© un modÃ¨le transformer appelÃ© ELECTRA. Ce modÃ¨le est un peu particulier : pour sâ€™entraÃ®ner, il joue Ã  un jeu oÃ¹ certains mots du texte sont remplacÃ©s par dâ€™autres, et le modÃ¨le doit deviner quels mots sont â€œfauxâ€. Cela lâ€™oblige Ã  comprendre finement la structure et le sens des phrases. Une fois ce modÃ¨le prÃ©-entraÃ®nÃ©, il peut Ãªtre spÃ©cialisÃ© pour des tÃ¢ches prÃ©cises, comme ici, prÃ©dire les traits de personnalitÃ© Ã  partir de courts textes.

Ce qui rend ELECTRA particuliÃ¨rement intÃ©ressant, câ€™est quâ€™il est plus rapide et plus lÃ©ger que ses prÃ©dÃ©cesseurs, tout en maintenant une trÃ¨s bonne prÃ©cision. De plus, il sâ€™agit dâ€™un modÃ¨le open-source, ce qui signifie que toute personne intÃ©ressÃ©e â€“ chercheurÂ·e, praticienÂ·ne ou Ã©tudiantÂ·e â€“ peut librement le consulter, lâ€™utiliser ou lâ€™adapter. Il est accessible sur des plateformes comme Hugging Face, favorisant ainsi la dÃ©mocratisation de lâ€™intelligence artificielle en recherche psychologique. Il est donc adaptÃ© Ã  des tÃ¢ches comme lâ€™analyse psychologique automatisÃ©e, oÃ¹ lâ€™on dispose souvent de quantitÃ©s modÃ©rÃ©es de donnÃ©es et oÃ¹ lâ€™interprÃ©tabilitÃ© est essentielle.

## Comment lâ€™Ã©tude a Ã©tÃ© rÃ©alisÃ©e

Les chercheurÂ·es ont utilisÃ© une base de donnÃ©es appelÃ©e Pennebaker and King Essays. On y trouve 2 467 petits textes Ã©crits librement par des adultes, souvent sous forme de rÃ©cits introspectifs ou de rÃ©flexions personnelles. Chacun de ces textes est accompagnÃ© dâ€™un profil de personnalitÃ© Ã©tabli par questionnaire, basÃ© sur le modÃ¨le des Big Five.

Voici comment ils ont procÃ©dÃ© :

1.  **PrÃ©traitement** : Les textes bruts ont d'abord Ã©tÃ© nettoyÃ©s pour les rendre exploitables par le modÃ¨le. Cela inclut la suppression de caractÃ¨res non alphabÃ©tiques, la normalisation des espaces et ponctuations, et la mise en forme uniforme des textes. Un seuil de longueur a Ã©galement Ã©tÃ© fixÃ© pour limiter la variabilitÃ© et standardiser l'entrÃ©e dans le modÃ¨le.

2.  **Augmentation** : Pour compenser la taille relativement modeste du corpus, les chercheurÂ·es ont eu recours Ã  une technique dâ€™augmentation de donnÃ©es. Celle-ci consiste Ã  remplacer certains mots par des synonymes pertinents, extraits de WordNet, de maniÃ¨re alÃ©atoire mais contrÃ´lÃ©e (jusquâ€™Ã  deux remplacements par phrase). Cela permet dâ€™augmenter la diversitÃ© lexicale tout en conservant le sens gÃ©nÃ©ral du texte, ce qui amÃ©liore la robustesse du modÃ¨le lors de la gÃ©nÃ©ralisation Ã  de nouveaux Ã©chantillons.

3.  **EntraÃ®nement** : Cinq modÃ¨les ELECTRA distincts ont Ã©tÃ© entraÃ®nÃ©s, chacun dÃ©diÃ© Ã  la prÃ©diction dâ€™un des cinq traits de personnalitÃ©. En procÃ©dant ainsi, les auteurÂ·es ont Ã©vitÃ© les interfÃ©rences possibles entre traits (par exemple entre agrÃ©abilitÃ© et consciencieux) et ont permis au modÃ¨le dâ€™apprendre des reprÃ©sentations linguistiques spÃ©cifiques Ã  chaque dimension. L'entraÃ®nement a Ã©tÃ© rÃ©alisÃ© en utilisant un algorithme d'optimisation de type AdamW, avec une stratÃ©gie de rÃ©gularisation pour Ã©viter le surapprentissage.

4.  **Ã‰valuation** : Les performances des modÃ¨les ont Ã©tÃ© mesurÃ©es Ã  lâ€™aide dâ€™un dÃ©coupage standard des donnÃ©es en ensembles dâ€™entraÃ®nement, de validation et de test. Plusieurs mÃ©triques ont Ã©tÃ© utilisÃ©es : prÃ©cision, rappel, score F1 et AUC (aire sous la courbe ROC). Ces indicateurs ont permis de sâ€™assurer que les modÃ¨les ne se contentaient pas de bien performer sur les donnÃ©es apprises, mais Ã©taient capables de gÃ©nÃ©raliser sur de nouveaux textes.

## Les rÃ©sultats

Les modÃ¨les ont obtenu de trÃ¨s bons rÃ©sultats, surpassant les performances dâ€™anciennes approches comme lâ€™analyse lexicale manuelle. Chaque dimension de la personnalitÃ© a Ã©tÃ© considÃ©rÃ©e indÃ©pendamment comme une tÃ¢che de classification binaire (par exemple, distinguer un haut dâ€™un bas niveau dâ€™extraversion), avec une Ã©valuation basÃ©e sur plusieurs mÃ©triques : prÃ©cision, rappel, score F1 et AUC (aire sous la courbe ROC).

Pour **lâ€™extraversion**, le modÃ¨le a obtenu une prÃ©cision de 78 %, avec une AUC remarquable de 0.84. Cela indique quâ€™il distingue bien les personnes extraverties des introverties, en captant des indices comme lâ€™usage frÃ©quent de la premiÃ¨re personne, lâ€™expressivitÃ© et les Ã©motions positives.

Pour **lâ€™ouverture Ã  lâ€™expÃ©rience**, la performance atteint 75 %. Le modÃ¨le semble particuliÃ¨rement sensible Ã  la richesse lexicale, Ã  la prÃ©sence de mots abstraits ou Ã  lâ€™usage de tournures stylistiques variÃ©es, souvent associÃ©es Ã  ce trait.

Concernant **lâ€™agrÃ©abilitÃ©**, le modÃ¨le atteint Ã©galement 74 % de prÃ©cision, avec une AUC solide. Il semble repÃ©rer des expressions de politesse, des tournures conciliantes et un ton globalement prosocial.

Pour **le nÃ©vrosisme**, le score de 74 % reflÃ¨te une bonne capacitÃ© Ã  dÃ©tecter les marqueurs de tension Ã©motionnelle, comme les mots associÃ©s Ã  lâ€™inquiÃ©tude, au doute ou Ã  la frustration.

Enfin, **la conscienciositÃ©** est le trait oÃ¹ le modÃ¨le obtient la prÃ©cision la plus faible (72 %), mais tout de mÃªme supÃ©rieure aux standards classiques. Ce trait semble plus difficile Ã  infÃ©rer Ã  partir de textes courts, car il repose sur des indices moins saillants, comme la structure syntaxique, la rÃ©gularitÃ© ou lâ€™organisation du discours.

Ces rÃ©sultats sont dâ€™autant plus notables que les textes analysÃ©s sont brefs, spontanÃ©s, et Ã©crits dans un cadre non contraint. La capacitÃ© du modÃ¨le Ã  extraire de tels signaux Ã  partir dâ€™un matÃ©riau aussi variable illustre la puissance de cette approche.

## Pourquoi câ€™est prometteur pour la psychologie

### 1. Un outil prÃ©cieux pour la recherche

Les chercheurÂ·es en psychologie manipulent souvent de grandes quantitÃ©s de textes â€” que ce soit des rÃ©ponses ouvertes Ã  des questionnaires, des journaux personnels, ou des messages sur des forums en ligne. Analyser tout cela manuellement peut prendre des semaines. GrÃ¢ce Ã  des modÃ¨les comme ELECTRA, on peut obtenir une premiÃ¨re lecture automatisÃ©e de ces textes : le modÃ¨le identifie les tournures, les mots ou les styles dâ€™Ã©criture qui pourraient Ãªtre liÃ©s Ã  certains traits de personnalitÃ©. Cela permet de gagner du temps, dâ€™Ã©largir le champ des Ã©tudes, et de formuler de nouvelles hypothÃ¨ses Ã  partir de donnÃ©es linguistiques quâ€™on aurait autrement nÃ©gligÃ©es.

### 2. Un soutien pour les pratiques cliniques et communautaires

Dans des contextes comme la clinique, lâ€™intervention communautaire ou mÃªme lâ€™Ã©ducation, il est souvent utile de comprendre rapidement le vÃ©cu ou le profil dâ€™une personne, surtout quand le contact est bref ou se fait en ligne. Un outil comme ELECTRA pourrait, par exemple, analyser de maniÃ¨re discrÃ¨te les premiÃ¨res rÃ©ponses Ã©crites dâ€™une personne sur une plateforme de soutien ou dans un formulaire dâ€™accueil. Il pourrait ainsi suggÃ©rer certains indicateurs linguistiques liÃ©s Ã  lâ€™anxiÃ©tÃ©, Ã  lâ€™agrÃ©abilitÃ© ou Ã  lâ€™ouverture dâ€™esprit, ce qui permettrait aux intervenantÂ·es dâ€™adapter leur approche. Cela ne remplace pas le jugement professionnel, mais cela peut offrir un regard complÃ©mentaire, plus subtil, pour guider la relation dâ€™aide.

### 3. Vers des technologies plus sensibles aux personnes

Cette technologie pourrait aussi transformer les interfaces numÃ©riques elles-mÃªmes. Imaginez un agent conversationnel (chatbot) qui ajuste son style de rÃ©ponse selon la personnalitÃ© perÃ§ue de la personne avec qui il Ã©change : plus chaleureux, plus structurÃ©, plus crÃ©atifâ€¦ Un tel ajustement pourrait rendre les interactions plus naturelles et plus humaines. Câ€™est une faÃ§on de concevoir lâ€™IA non pas comme un outil froid et distant, mais comme un alliÃ© dans la crÃ©ation de liens, capable de mieux comprendre et de mieux sâ€™adapter aux personnes.

## Et les limites?

Ã‰videmment, tout nâ€™est pas parfait :

-   Lâ€™algorithme fonctionne surtout sur des textes en anglais, Ã©crits par une population assez homogÃ¨ne.
-   Il ne prend en compte que le texte, pas le ton de la voix, le contexte, ni les Ã©motions ressenties.
-   Le modÃ¨le peut surapprendre Ã  ses exemples, ce qui limite parfois sa gÃ©nÃ©ralisation.

Mais ces dÃ©fis sont connus, et les auteurÂ·es proposent plusieurs pistes pour y remÃ©dier (donnÃ©es plus variÃ©es, donnÃ©es multimodales, etc.).

Lâ€™article complet est disponible ici : **Saberi, H., Ghofrani, S., & Ravanmehr, R. (2025)**. *Personality Recognition Using Transformer Model: A Study on the Big Five Traits*. IEEE ICWR. ğŸ”— [AccÃ¨s via IEEE Xplore](https://ieeexplore.ieee.org/document/11006181)

<!-- Formulaire dâ€™abonnement Brevo -->
<iframe width="540" height="405" scrolling ="no" src="https://sibforms.com/serve/MUIFAJuXpDvH14nAsFXhXmM7v_z4nHcpDJCxRYobbS4dO7G-ovnmEkzoaPhHHEKEPAWRf3EVMvbOumRBiEsM6A50GTewyamCczEPOkwY9jSzdOIhDlnGvyrZJq7_DnhQswAXMCQ4QhEhVv0wZoQ_S-DisWk4a4YeHj6TW3XrELrEZPr4Nv-e2EJt60iSgcFerHiFJzCrIkdm7njy" frameborder="0" scrolling="auto" allowfullscreen style="display: block;margin-left: auto;margin-right: auto;max-width: 100%;"></iframe>
