---
title: "ReconnaÃ®tre la personnalitÃ© Ã  partir de textes? Une Ã©tude prometteuse avec les modÃ¨les transformers"
description: "Que peut rÃ©vÃ©ler un court texte sur la personnalitÃ© de son auteur? GrÃ¢ce aux modÃ¨les transformers, lâ€™intelligence artificielle commence Ã  rÃ©pondre Ã  cette question avec une prÃ©cision surprenante."
categories: ["Science des donnÃ©es & psychologie", "IA gÃ©nÃ©rative & cognition"]
date: 2025-05-26
---

## Introduction

Peut-on prÃ©dire les traits de personnalitÃ© dâ€™une personne simplement Ã  partir dâ€™un texte quâ€™elle a Ã©crit? Cette question, qui pourrait sembler tirÃ©e dâ€™un film de science-fiction, est aujourdâ€™hui au cÅ“ur de recherches sÃ©rieuses en psychologie computationnelle. Jâ€™ai rÃ©cemment lu une Ã©tude fascinante prÃ©sentÃ©e Ã  la confÃ©rence *IEEE ICWR 2025*, qui explore cette idÃ©e Ã  lâ€™aide dâ€™un modÃ¨le dâ€™intelligence artificielle appelÃ© **ELECTRA**, une version moderne des modÃ¨les transformers.

Dans ce billet, je prÃ©sente lâ€™article en question ainsi que la technologie dâ€™intelligence artificielle qui permet dâ€™analyser les textes pour en extraire des indices de personnalitÃ©.

## Un peu de contexte : les traits de personnalitÃ©

Dans cet article, les auteurs cherchent Ã  prÃ©dire les traits de personnalitÃ© en fonction du modÃ¨le des **Big Five** ou Â« cinq grands facteurs Â» de la personnalitÃ©. Ce modÃ¨le propose cinq traits fondamentaux :

* **Ouverture Ã  lâ€™expÃ©rience** : imagination, curiositÃ©, crÃ©ativitÃ©
* **Consciencieux** : organisation, rigueur, discipline
* **Extraversion** : sociabilitÃ©, expressivitÃ©, dynamisme
* **AgrÃ©abilitÃ©** : bienveillance, coopÃ©ration, empathie
* **NÃ©vrosisme** : tendance Ã  lâ€™anxiÃ©tÃ©, la colÃ¨re ou la tristesse

Dans la recherche, on tente souvent de relier ces traits Ã  la maniÃ¨re dont une personne parle ou Ã©crit. Par exemple, quelquâ€™un de trÃ¨s extraverti pourrait utiliser plus de mots liÃ©s Ã  lâ€™Ã©motion ou Ã  la premiÃ¨re personne (Â« je Â», Â« moi Â»), tandis quâ€™une personne trÃ¨s nÃ©vrosÃ©e pourrait employer davantage de mots Ã  connotation nÃ©gative.

## Avant les transformers : premiÃ¨res tentatives dâ€™analyse de la personnalitÃ© Ã  partir du texte

### Des approches symboliques fondÃ©es sur les mots

Avant lâ€™essor de lâ€™apprentissage profond, les chercheurÂ·es ont tentÃ© dâ€™utiliser des approches plus classiques de lâ€™intelligence artificielle pour analyser le lien entre langage et personnalitÃ©. Ces mÃ©thodes â€” souvent fondÃ©es sur des rÃ¨gles simples ou des statistiques â€” reprÃ©sentent les **premiers pas de lâ€™IA appliquÃ©e Ã  la psychologie du langage**. MÃªme si elles Ã©taient moins performantes que les approches modernes, elles ont posÃ© les bases de ce champ en plein essor : faire parler les textes pour mieux comprendre qui les Ã©crit.

Les premiÃ¨res tentatives pour relier le langage Ã©crit aux traits de personnalitÃ© ont reposÃ© sur des approches dites symboliques ou statistiques. Lâ€™une des plus connues est lâ€™utilisation de **LIWC** (*Linguistic Inquiry and Word Count*), un outil qui scanne un texte et compte la frÃ©quence de certains types de mots, comme ceux associÃ©s Ã  la colÃ¨re, Ã  la famille, aux Ã©motions positives ou nÃ©gatives. En analysant ces frÃ©quences, les chercheurÂ·es pouvaient Ã©tablir des liens avec des traits de personnalitÃ©. Par exemple, une personne utilisant souvent des mots chargÃ©s dâ€™Ã©motion positive pouvait Ãªtre perÃ§ue comme plus extravertie, alors quâ€™un vocabulaire plus anxiogÃ¨ne Ã©tait frÃ©quemment associÃ© au nÃ©vrosisme.

### Des modÃ¨les statistiques plus flexibles

En parallÃ¨le, des mÃ©thodes plus statistiques se sont dÃ©veloppÃ©es. Des modÃ¨les comme les **forÃªts alÃ©atoires**, les **rÃ©seaux de neurones artificiels simples** ou les **SVM (support vector machines)** ont Ã©tÃ© utilisÃ©s pour prÃ©dire les traits de personnalitÃ© Ã  partir de caractÃ©ristiques linguistiques extraites manuellement. Ces caractÃ©ristiques incluaient, par exemple, le nombre de phrases, la longueur moyenne des mots, la frÃ©quence dâ€™utilisation de certains temps verbaux, ou encore la proportion de pronoms personnels. Ces approches, bien que plus souples que les analyses par mots-clÃ©s, restaient fortement dÃ©pendantes des choix faits par les chercheurs en amont : il fallait dÃ©finir quoi mesurer, et comment.

### Les limites de ces approches

Cependant, ces premiÃ¨res mÃ©thodes prÃ©sentaient plusieurs limites importantes. Dâ€™abord, elles sâ€™appuyaient sur de nombreuses hypothÃ¨ses implicites : il fallait deviner Ã  lâ€™avance quels Ã©lÃ©ments du langage pourraient Ãªtre liÃ©s Ã  la personnalitÃ©. Ensuite, elles Ã©taient peu sensibles au contexte. Un mot comme Â« froid Â», par exemple, nâ€™aura pas le mÃªme sens selon quâ€™il dÃ©crit la mÃ©tÃ©o ou une relation humaine. Ces modÃ¨les peinaient donc Ã  saisir les subtilitÃ©s du langage naturel. Enfin, leurs performances plafonnaient souvent autour de 65 Ã  70 % de prÃ©cision, ce qui limitait leur utilitÃ© dans des contextes plus complexes ou variÃ©s. Câ€™est prÃ©cisÃ©ment pour dÃ©passer ces limites que les chercheurs se sont tournÃ©s vers des approches plus flexibles et puissantes, comme celles fondÃ©es sur le deep learning. Parmi elles, les modÃ¨les transformers marquent une avancÃ©e majeure.

## Comprendre les transformers (sans Ã©quation!)

[contenu dÃ©jÃ  inclus]

## Comment lâ€™Ã©tude a Ã©tÃ© rÃ©alisÃ©e

[contenu dÃ©jÃ  inclus]

## Les rÃ©sultats en langage simple

[contenu dÃ©jÃ  inclus]

## Pourquoi câ€™est prometteur pour la psychologie

[contenu dÃ©jÃ  inclus]

## Et les limites?

Ã‰videmment, tout nâ€™est pas parfait :

* Lâ€™algorithme fonctionne surtout sur **des textes en anglais**, Ã©crits par une population assez homogÃ¨ne.
* Il ne prend en compte **que le texte**, pas le ton de la voix, le contexte, ni les Ã©motions ressenties.
* Le modÃ¨le peut **surapprendre** Ã  ses exemples, ce qui limite parfois sa gÃ©nÃ©ralisation.

Mais ces dÃ©fis sont connus, et les auteurÂ·es proposent plusieurs pistes pour y remÃ©dier (donnÃ©es plus variÃ©es, donnÃ©es multimodales, etc.).

## Conclusion

Cette Ã©tude nous montre que des modÃ¨les comme ELECTRA peuvent **apprendre Ã  â€œread between the linesâ€**, et identifier des **indices subtils de la personnalitÃ©** dans les textes. Cela ne remplace pas une Ã©valuation clinique, bien sÃ»r, mais cela ouvre la voie Ã  des outils hybrides, oÃ¹ **lâ€™IA soutient lâ€™humain**.

Je continuerai dâ€™explorer ces liens entre langage, psychologie et IA dans ce blogue. Nâ€™hÃ©sitez pas Ã  mâ€™Ã©crire si vous souhaitez que jâ€™aborde un sujet en particulier!

Lâ€™article complet est disponible ici :
**Saberi, H., Ghofrani, S., & Ravanmehr, R. (2025)**. *Personality Recognition Using Transformer Model: A Study on the Big Five Traits*. IEEE ICWR.
ğŸ”— [AccÃ¨s via IEEE Xplore](https://ieeexplore.ieee.org/document/11006181)
